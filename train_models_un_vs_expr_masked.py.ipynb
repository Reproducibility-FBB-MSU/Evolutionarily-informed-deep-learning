{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание неэкспрессирующихся и экспрессирующихся генов.\n",
    "Предсказание использует: 1500bp промотора, 1500bp терминатора или оба\n",
    "Неэкспрессирующиеся гены помеченны как 1\n",
    "Экспрессирующиеся гены помеченны как 0.\n",
    "Для того, чтобы запустить обучение нейронной сети, понадобится:\n",
    "python 2\n",
    "tensorflow 1.10.1\n",
    "keras 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Bio.SeqIO\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from sys import argv\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout,Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential,Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from itertools import izip\n",
    "from datetime import datetime\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пути до необходимых библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные файлы с последовательностями промоторов и терминаторов генов храняться по ссылке:\n",
    "    https://de.cyverse.org/dl/d/0F63CD73-C1BE-4588-8FEF-E9EF57FCA117/data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_FILE_PRO='../../../data/pseudogene_model_data/promoters.fa'\n",
    "SEQ_FILE_PRO_DSHUFFLE='../../../data/pseudogene_model_data/promoters.dishuffle.fa'\n",
    "SEQ_FILE_TER='../../../data/pseudogene_model_data/terminators.fa'\n",
    "SEQ_FILE_TER_DSHUFFLE='../../../data/pseudogene_model_data/terminators.dishuffle.fa'\n",
    "DATA_FILE='../../../data/pseudogene_model_data/un_vs_expr.csv'\n",
    "RESULT_DIRECTORY='../../../data/pseudogene_model_data/trained_models_un_vs_expr/'\n",
    "\n",
    "if not os.path.exists(RESULT_DIRECTORY):\n",
    "   os.makedirs(RESULT_DIRECTORY)\n",
    "\n",
    "data=pd.read_csv(DATA_FILE,sep='\\t')\n",
    "data=data.set_index('Geneid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры входных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geneid</th>\n",
       "      <th>max_TPM</th>\n",
       "      <th>category</th>\n",
       "      <th>family_index</th>\n",
       "      <th>subsample_assignment1</th>\n",
       "      <th>subsample_assignment2</th>\n",
       "      <th>subsample_assignment3</th>\n",
       "      <th>subsample_assignment4</th>\n",
       "      <th>subsample_assignment5</th>\n",
       "      <th>subsample_assignment6</th>\n",
       "      <th>subsample_assignment7</th>\n",
       "      <th>subsample_assignment8</th>\n",
       "      <th>subsample_assignment9</th>\n",
       "      <th>subsample_assignment10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRMZM2G001361</td>\n",
       "      <td>2.329850</td>\n",
       "      <td>expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRMZM2G349834</td>\n",
       "      <td>2.840039</td>\n",
       "      <td>expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRMZM2G367267</td>\n",
       "      <td>3.059058</td>\n",
       "      <td>expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRMZM2G333619</td>\n",
       "      <td>6.598894</td>\n",
       "      <td>expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRMZM2G023399</td>\n",
       "      <td>6.788201</td>\n",
       "      <td>expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Geneid   max_TPM   category  family_index subsample_assignment1  \\\n",
       "0  GRMZM2G001361  2.329850  expressed             0            subsample2   \n",
       "1  GRMZM2G349834  2.840039  expressed             0            subsample2   \n",
       "2  GRMZM2G367267  3.059058  expressed             0            subsample2   \n",
       "3  GRMZM2G333619  6.598894  expressed             0            subsample2   \n",
       "4  GRMZM2G023399  6.788201  expressed             0            subsample2   \n",
       "\n",
       "  subsample_assignment2 subsample_assignment3 subsample_assignment4  \\\n",
       "0            subsample4            subsample2            subsample1   \n",
       "1            subsample4            subsample2            subsample1   \n",
       "2            subsample4            subsample2            subsample1   \n",
       "3            subsample4            subsample2            subsample1   \n",
       "4            subsample4            subsample2            subsample1   \n",
       "\n",
       "  subsample_assignment5 subsample_assignment6 subsample_assignment7  \\\n",
       "0            subsample1            subsample2            subsample3   \n",
       "1            subsample1            subsample2            subsample3   \n",
       "2            subsample1            subsample2            subsample3   \n",
       "3            subsample1            subsample2            subsample3   \n",
       "4            subsample1            subsample2            subsample3   \n",
       "\n",
       "  subsample_assignment8 subsample_assignment9 subsample_assignment10  \n",
       "0            subsample4            subsample2             subsample2  \n",
       "1            subsample4            subsample2             subsample2  \n",
       "2            subsample4            subsample2             subsample2  \n",
       "3            subsample4            subsample2             subsample2  \n",
       "4            subsample4            subsample2             subsample2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "gene_df=pd.read_csv(\"un_vs_expr.csv\", sep=\"\\t\")\n",
    "gene_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание пустых списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneIDs=[]\n",
    "categories=[]\n",
    "\n",
    "seqs=[]\n",
    "seqs_pro=[]\n",
    "seqs_ter=[]\n",
    "\n",
    "seqs_dshuffle=[]\n",
    "seqs_pro_dshuffle=[]\n",
    "seqs_ter_dshuffle=[]\n",
    "\n",
    "seqs_sshuffle=[]\n",
    "seqs_pro_sshuffle=[]\n",
    "seqs_ter_sshuffle=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочтение последовательностей и генерирование перемешанных последовательностей. Перемешивание последовательностей\n",
    "происходит двумя типами: однонуклеотидное и двунуклеотидное. Это действие производиться для того, чтобы убрать\n",
    "биологических смысл последовательности и посмотреть, что CNN найдет в данных, лищенных смысла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in izip(Bio.SeqIO.parse(SEQ_FILE_PRO,'fasta'), Bio.SeqIO.parse(SEQ_FILE_TER,'fasta') ):\n",
    "     geneID=x.id\n",
    "\n",
    "     seq_pro=x.seq.tostring()\n",
    "     seq_pro_sshuffle=list(seq_pro)\n",
    "     random.shuffle(seq_pro_sshuffle)\n",
    "     seq_pro_sshuffle=''.join(seq_pro_sshuffle)\n",
    "\n",
    "     seq_ter=y.seq.tostring()\n",
    "     seq_ter_sshuffle=list(seq_ter)\n",
    "     random.shuffle(seq_ter_sshuffle)\n",
    "     seq_ter_sshuffle=''.join(seq_ter_sshuffle)\n",
    "\n",
    "     seq=seq_pro+seq_ter\n",
    "     seq_sshuffle=seq_pro_sshuffle+seq_ter_sshuffle\n",
    "\n",
    "     if geneID in data.index:\n",
    "         seqs.append(seq)\n",
    "         seqs_sshuffle.append(seq_sshuffle)\n",
    "         seqs_pro.append(seq_pro)\n",
    "         seqs_pro_sshuffle.append(seq_pro_sshuffle)\n",
    "         seqs_ter.append(seq_ter)\n",
    "         seqs_ter_sshuffle.append(seq_ter_sshuffle)\n",
    "         geneIDs.append(geneID)\n",
    "         category=data['category'][geneID]\n",
    "         if category=='expressed':\n",
    "              categories.append(0)\n",
    "         else:\n",
    "              categories.append(1)\n",
    "\n",
    "for x,y in izip(Bio.SeqIO.parse(SEQ_FILE_PRO_DSHUFFLE,'fasta'), Bio.SeqIO.parse(SEQ_FILE_TER_DSHUFFLE,'fasta') ):\n",
    "     geneID=x.id\n",
    "     seq_pro_dshuffle=x.seq.tostring()\n",
    "     seq_ter_dshuffle=y.seq.tostring()\n",
    "     seq_dshuffle=seq_pro_dshuffle+seq_ter_dshuffle\n",
    "     if geneID in data.index:\n",
    "         seqs_dshuffle.append(seq_dshuffle)\n",
    "         seqs_pro_dshuffle.append(seq_pro_dshuffle)\n",
    "         seqs_ter_dshuffle.append(seq_ter_dshuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе каждая последовательность кодируется матрицей размером 4Хдлина последовательности.\n",
    "Чтобы исключить влияние таких очевидных вещей как старт или стоп кодон они маскируются нулями. \n",
    "Нейронная сеть не должна опираться на эти очевидные признаки, тк во многих данных может быть потеряны старты/стопы\n",
    "транскрипции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],'T':[0,0,0,1]}\n",
    "\n",
    "def one_hot_encoding(seq):\n",
    "    one_hot_encoded=np.zeros(shape=(4,len(seq)))\n",
    "    for i,nt in enumerate(seq):\n",
    "        one_hot_encoded[:,i]=dict[nt]\n",
    "    return one_hot_encoded\n",
    "\n",
    "one_hot_seqs=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs],dtype=np.float32),3)\n",
    "one_hot_seqs_pro=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro],dtype=np.float32),3)\n",
    "one_hot_seqs_ter=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter],dtype=np.float32),3)\n",
    "\n",
    "\n",
    "one_hot_seqs[:,:,1000:1003,:]=0\n",
    "one_hot_seqs[:,:,1997:2000,:]=0\n",
    "one_hot_seqs_pro[:,:,1000:1003,:]=0\n",
    "one_hot_seqs_ter[:,:,497:500,:]=0\n",
    "\n",
    "one_hot_seqs_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_dshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_pro_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro_dshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_ter_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter_dshuffle],dtype=np.float32),3)\n",
    "\n",
    "one_hot_seqs_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_sshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_pro_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro_sshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_ter_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter_sshuffle],dtype=np.float32),3)\n",
    "\n",
    "geneIDs=np.array(geneIDs)\n",
    "categories=np_utils.to_categorical(np.array(categories),2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура нейронной сети: \n",
    "Три группы из двух сверточных слоев, \n",
    "одного пуллингового и одного dropout-слоя. Они формируют вектор признаков \n",
    "для полносвязных слоев стандартной нейронной сети (представленной в самом конце). \n",
    "Далее нейронная сеть состоит из двух полносвязных \n",
    "слоев с dropout и из решающего слоя. Везде активационные функции - это ReLU, кроме решающего слоя, \n",
    "где использована softmax функция.\n",
    "Пуллинг и дропаут слои позволяют, в том числе, не переобучать слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(window_size):\n",
    "                model=Sequential()\n",
    "\n",
    "                model.add(Conv2D(64,kernel_size=(4,8),padding='valid',input_shape=[4,window_size,1]))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Conv2D(128,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(128,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(128))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dropout(0.25))\n",
    "                model.add(Dense(64))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dense(2))\n",
    "                model.add(Activation('softmax'))\n",
    "                return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели\n",
    "Распределение на обучающую и тестовую выборку\n",
    "EarlyStopping строка позволяет остановить обучение если потеря данных больше некоторого порога. Поэтому нейросеть\n",
    "может останавливаться и не доходить до конца по мере обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(TRAINING_ONE_HOT_SEQS,TESTING_ONE_HOT_SEQS,training_indices,testing_indices,split,test_subsample,shuffle,predictor):\n",
    "      \n",
    "      TRAINING_ONE_HOT_SEQS=TRAINING_ONE_HOT_SEQS[training_indices]\n",
    "      TESTING_ONE_HOT_SEQS=TESTING_ONE_HOT_SEQS[testing_indices]\n",
    "      TRAINING_CATEGORIES=categories[training_indices]\n",
    "      TESTING_CATEGORIES=categories[testing_indices]\n",
    "      TESTING_GENES=geneIDs[testing_indices]\n",
    "\n",
    "      LENGTH=TRAINING_ONE_HOT_SEQS.shape[2]\n",
    "      \n",
    "      callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0)]\n",
    "      model=build(LENGTH)\n",
    "      model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "      model.fit(x=TRAINING_ONE_HOT_SEQS,y=TRAINING_CATEGORIES,batch_size=256,epochs=40,validation_data=(TESTING_ONE_HOT_SEQS,TESTING_CATEGORIES),callbacks=callbacks)\n",
    "\n",
    "      prediction=model.predict(TESTING_ONE_HOT_SEQS)\n",
    "      predicted_categories= np.argmax(prediction,axis=1)\n",
    "      real_categories=np.argmax(TESTING_CATEGORIES,axis=1)\n",
    "      tn,fp,fn,tp=confusion_matrix(real_categories,predicted_categories).ravel()\n",
    "      test_total=tp+tn+fp+fn\n",
    "      accuracy=(tp+tn)/(test_total*1.0)\n",
    "\n",
    "      now=datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "      model.save(RESULT_DIRECTORY+\"MODEL_\"+now)\n",
    "      pickle.dump([TESTING_GENES,TESTING_CATEGORIES,prediction],open(RESULT_DIRECTORY+\"PICKLE_\"+now,'wb'))\n",
    "      with open(RESULT_DIRECTORY+'SUMMARY_FILE', \"a\") as result_file:\n",
    "         result_file.write(\"\\t\".join([now,split,test_subsample,shuffle,str(tp),str(tn),str(fp),str(fn),str(accuracy),str(test_total),predictor]))\n",
    "         result_file.write(\"\\n\")\n",
    "      del model\n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для статистически достоверной оценки работы модели она запускается 10 раз (каждый раз) с 5-фолд кросс-валидацией. \n",
    "(При разбиении выборки учитываются семейства).\n",
    "Три типа данных: PROMOTER, TERMINATOR, PROMOTER+TERMINATOR.\n",
    "Во время запуска обеспечивается динуклеотидное и мононуклеотидное перемешивание данных обучения.\n",
    "Всего тренируется 10*5*3*3=450 моделей.\n",
    "В тестовой и тренировочной выборках производят балансировку, то есть оставляют равное количество неэкспрессируемых и \n",
    "экспрессируемых генов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "splits=data.columns.values[-10:]\n",
    "subsamples=['subsample1','subsample2','subsample3','subsample4','subsample5']\n",
    "\n",
    "for split in splits:\n",
    "   for test_subsample in subsamples:\n",
    "       testing_genes = data[data[split]==test_subsample].index\n",
    "       testing_genes = np.array(list(set(testing_genes).intersection(set(geneIDs))))\n",
    "       \n",
    "       unexpressed_testing_genes=[gene for gene in testing_genes if data['category'][gene]=='unexpressed'  ]\n",
    "       expressed_testing_genes=[gene for gene in testing_genes if data['category'][gene]=='expressed']\n",
    "       expressed_testing_genes=np.random.choice(expressed_testing_genes,len(unexpressed_testing_genes),replace=False)\n",
    "       testing_genes=np.concatenate((expressed_testing_genes,unexpressed_testing_genes),axis=0)\n",
    "\n",
    "       training_genes= data[data[split]!=test_subsample].index\n",
    "       training_genes= np.array(list(set(training_genes).intersection(set(geneIDs))))\n",
    "       \n",
    "       unexpressed_training_genes=[gene for gene in training_genes if data['category'][gene]=='unexpressed'  ]\n",
    "       expressed_training_genes=[gene for gene in training_genes if data['category'][gene]=='expressed']\n",
    "       expressed_training_genes=np.random.choice(expressed_training_genes,len(unexpressed_training_genes),replace=False)\n",
    "       training_genes=np.concatenate((expressed_training_genes,unexpressed_training_genes),axis=0)\n",
    "\n",
    "       training_indices=np.array([np.where(geneIDs==element)[0][0] for element in training_genes])\n",
    "       testing_indices=np.array([np.where(geneIDs==element)[0][0] for element in testing_genes])\n",
    "       np.random.shuffle(training_indices)\n",
    "       train_models(one_hot_seqs,               one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'None','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro,           one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'None','Pro')\n",
    "       train_models(one_hot_seqs_ter,           one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'None','Ter')\n",
    "       train_models(one_hot_seqs_dshuffle,      one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'D_Shuffle','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro_dshuffle,  one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'D_Shuffle','Pro')\n",
    "       train_models(one_hot_seqs_ter_dshuffle,  one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'D_Shuffle','Ter')\n",
    "       train_models(one_hot_seqs_sshuffle,      one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'S_Shuffle','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro_sshuffle,  one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'S_Shuffle','Pro')\n",
    "       train_models(one_hot_seqs_ter_sshuffle,  one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'S_Shuffle','Ter')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе, после обучения нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20190519135331</th>\n",
       "      <th>subsample_assignment1</th>\n",
       "      <th>subsample1</th>\n",
       "      <th>None</th>\n",
       "      <th>575</th>\n",
       "      <th>531</th>\n",
       "      <th>221</th>\n",
       "      <th>177</th>\n",
       "      <th>0.7353723404255319</th>\n",
       "      <th>1504</th>\n",
       "      <th>Pro_and_Ter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190519135843</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>None</td>\n",
       "      <td>568</td>\n",
       "      <td>452</td>\n",
       "      <td>300</td>\n",
       "      <td>184</td>\n",
       "      <td>0.678191</td>\n",
       "      <td>1504</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190519140625</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>None</td>\n",
       "      <td>592</td>\n",
       "      <td>442</td>\n",
       "      <td>310</td>\n",
       "      <td>160</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1504</td>\n",
       "      <td>Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190519141215</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>39</td>\n",
       "      <td>720</td>\n",
       "      <td>32</td>\n",
       "      <td>713</td>\n",
       "      <td>0.504654</td>\n",
       "      <td>1504</td>\n",
       "      <td>Pro_and_Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190519141435</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1504</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190519141805</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1504</td>\n",
       "      <td>Ter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   20190519135331  subsample_assignment1  subsample1       None  575  531  \\\n",
       "0  20190519135843  subsample_assignment1  subsample1       None  568  452   \n",
       "1  20190519140625  subsample_assignment1  subsample1       None  592  442   \n",
       "2  20190519141215  subsample_assignment1  subsample1  D_Shuffle   39  720   \n",
       "3  20190519141435  subsample_assignment1  subsample1  D_Shuffle  752    0   \n",
       "4  20190519141805  subsample_assignment1  subsample1  D_Shuffle  752    0   \n",
       "\n",
       "   221  177  0.7353723404255319  1504  Pro_and_Ter  \n",
       "0  300  184            0.678191  1504          Pro  \n",
       "1  310  160            0.687500  1504          Ter  \n",
       "2   32  713            0.504654  1504  Pro_and_Ter  \n",
       "3  752    0            0.500000  1504          Pro  \n",
       "4  752    0            0.500000  1504          Ter  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "gene_df=pd.read_csv(\"output_un_vs_expr.csv\", sep=\",\")\n",
    "gene_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
