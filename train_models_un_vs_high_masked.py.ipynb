{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предсказание неэкспрессирующихся и высоко-экспрессирующихся генов.\n",
    "Предсказание использует: 1500bp промотора, 1500bp терминатора или оба\n",
    "Неэкспрессирующиеся гены помеченны как 1\n",
    "Экспрессирующиеся гены помеченны как 0.\n",
    "Для того, чтобы запустить обучение нейронной сети, понадобится:\n",
    "python 2\n",
    "tensorflow 1.10.1\n",
    "keras 2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Bio.SeqIO\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import os\n",
    "from sys import argv\n",
    "from keras.metrics import mean_squared_error\n",
    "from keras.layers import Dense,Activation,Flatten,Dropout,Conv2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential,Model\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from itertools import izip\n",
    "from datetime import datetime\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пути до необходимых библиотек"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные файлы с последовательностями промоторов и терминаторов генов храняться по ссылке:\n",
    "    https://de.cyverse.org/dl/d/0F63CD73-C1BE-4588-8FEF-E9EF57FCA117/data.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SEQ_FILE_PRO='../../../data/pseudogene_model_data/promoters.fa'\n",
    "SEQ_FILE_PRO_DSHUFFLE='../../../data/pseudogene_model_data/promoters.dishuffle.fa'\n",
    "SEQ_FILE_TER='../../../data/pseudogene_model_data/terminators.fa'\n",
    "SEQ_FILE_TER_DSHUFFLE='../../../data/pseudogene_model_data/terminators.dishuffle.fa'\n",
    "DATA_FILE='../../../data/pseudogene_model_data/un_vs_high.csv'\n",
    "RESULT_DIRECTORY='../../../data/pseudogene_model_data/trained_models_un_high_expr/'\n",
    "\n",
    "if not os.path.exists(RESULT_DIRECTORY):\n",
    "   os.makedirs(RESULT_DIRECTORY)\n",
    "\n",
    "data=pd.read_csv(DATA_FILE,sep='\\t')\n",
    "data=data.set_index('Geneid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример входных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geneid</th>\n",
       "      <th>max_TPM</th>\n",
       "      <th>category</th>\n",
       "      <th>family_id</th>\n",
       "      <th>subsample_assignment1</th>\n",
       "      <th>subsample_assignment2</th>\n",
       "      <th>subsample_assignment3</th>\n",
       "      <th>subsample_assignment4</th>\n",
       "      <th>subsample_assignment5</th>\n",
       "      <th>subsample_assignment6</th>\n",
       "      <th>subsample_assignment7</th>\n",
       "      <th>subsample_assignment8</th>\n",
       "      <th>subsample_assignment9</th>\n",
       "      <th>subsample_assignment10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GRMZM2G002616</td>\n",
       "      <td>383.476196</td>\n",
       "      <td>highly-expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GRMZM2G112336</td>\n",
       "      <td>389.840179</td>\n",
       "      <td>highly-expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GRMZM2G150404</td>\n",
       "      <td>399.394257</td>\n",
       "      <td>highly-expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GRMZM2G142898</td>\n",
       "      <td>407.575531</td>\n",
       "      <td>highly-expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GRMZM2G022019</td>\n",
       "      <td>408.910858</td>\n",
       "      <td>highly-expressed</td>\n",
       "      <td>0</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample4</td>\n",
       "      <td>subsample2</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>subsample3</td>\n",
       "      <td>subsample5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Geneid     max_TPM          category  family_id  \\\n",
       "0  GRMZM2G002616  383.476196  highly-expressed          0   \n",
       "1  GRMZM2G112336  389.840179  highly-expressed          0   \n",
       "2  GRMZM2G150404  399.394257  highly-expressed          0   \n",
       "3  GRMZM2G142898  407.575531  highly-expressed          0   \n",
       "4  GRMZM2G022019  408.910858  highly-expressed          0   \n",
       "\n",
       "  subsample_assignment1 subsample_assignment2 subsample_assignment3  \\\n",
       "0            subsample2            subsample2            subsample3   \n",
       "1            subsample2            subsample2            subsample3   \n",
       "2            subsample2            subsample2            subsample3   \n",
       "3            subsample2            subsample2            subsample3   \n",
       "4            subsample2            subsample2            subsample3   \n",
       "\n",
       "  subsample_assignment4 subsample_assignment5 subsample_assignment6  \\\n",
       "0            subsample4            subsample4            subsample2   \n",
       "1            subsample4            subsample4            subsample2   \n",
       "2            subsample4            subsample4            subsample2   \n",
       "3            subsample4            subsample4            subsample2   \n",
       "4            subsample4            subsample4            subsample2   \n",
       "\n",
       "  subsample_assignment7 subsample_assignment8 subsample_assignment9  \\\n",
       "0            subsample3            subsample1            subsample3   \n",
       "1            subsample3            subsample1            subsample3   \n",
       "2            subsample3            subsample1            subsample3   \n",
       "3            subsample3            subsample1            subsample3   \n",
       "4            subsample3            subsample1            subsample3   \n",
       "\n",
       "  subsample_assignment10  \n",
       "0             subsample5  \n",
       "1             subsample5  \n",
       "2             subsample5  \n",
       "3             subsample5  \n",
       "4             subsample5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "gene_df=pd.read_csv(\"un_vs_high.csv\", sep=\"\\t\")\n",
    "gene_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание пустых списков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneIDs=[]\n",
    "categories=[]\n",
    "\n",
    "seqs=[]\n",
    "seqs_pro=[]\n",
    "seqs_ter=[]\n",
    "\n",
    "seqs_dshuffle=[]\n",
    "seqs_pro_dshuffle=[]\n",
    "seqs_ter_dshuffle=[]\n",
    "\n",
    "seqs_sshuffle=[]\n",
    "seqs_pro_sshuffle=[]\n",
    "seqs_ter_sshuffle=[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочтение последовательностей и генерирование перемешанных последовательностей. Перемешивание последовательностей\n",
    "происходит двумя типами: однонуклеотидное и двунуклеотидное. Это действие производиться для того, чтобы убрать\n",
    "биологических смысл последовательности и посмотреть, что CNN найдет в данных, лищенных смысла. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in izip(Bio.SeqIO.parse(SEQ_FILE_PRO,'fasta'), Bio.SeqIO.parse(SEQ_FILE_TER,'fasta') ):\n",
    "     geneID=x.id\n",
    "\n",
    "     seq_pro=x.seq.tostring()\n",
    "     seq_pro_sshuffle=list(seq_pro)\n",
    "     random.shuffle(seq_pro_sshuffle)\n",
    "     seq_pro_sshuffle=''.join(seq_pro_sshuffle)\n",
    "\n",
    "     seq_ter=y.seq.tostring()\n",
    "     seq_ter_sshuffle=list(seq_ter)\n",
    "     random.shuffle(seq_ter_sshuffle)\n",
    "     seq_ter_sshuffle=''.join(seq_ter_sshuffle)\n",
    "\n",
    "     seq=seq_pro+seq_ter\n",
    "     seq_sshuffle=seq_pro_sshuffle+seq_ter_sshuffle\n",
    "\n",
    "     if geneID in data.index:\n",
    "         seqs.append(seq)\n",
    "         seqs_sshuffle.append(seq_sshuffle)\n",
    "         seqs_pro.append(seq_pro)\n",
    "         seqs_pro_sshuffle.append(seq_pro_sshuffle)\n",
    "         seqs_ter.append(seq_ter)\n",
    "         seqs_ter_sshuffle.append(seq_ter_sshuffle)\n",
    "         geneIDs.append(geneID)\n",
    "         category=data['category'][geneID]\n",
    "         if category=='expressed':\n",
    "              categories.append(0)\n",
    "         else:\n",
    "              categories.append(1)\n",
    "\n",
    "for x,y in izip(Bio.SeqIO.parse(SEQ_FILE_PRO_DSHUFFLE,'fasta'), Bio.SeqIO.parse(SEQ_FILE_TER_DSHUFFLE,'fasta') ):\n",
    "     geneID=x.id\n",
    "     seq_pro_dshuffle=x.seq.tostring()\n",
    "     seq_ter_dshuffle=y.seq.tostring()\n",
    "     seq_dshuffle=seq_pro_dshuffle+seq_ter_dshuffle\n",
    "     if geneID in data.index:\n",
    "         seqs_dshuffle.append(seq_dshuffle)\n",
    "         seqs_pro_dshuffle.append(seq_pro_dshuffle)\n",
    "         seqs_ter_dshuffle.append(seq_ter_dshuffle)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На данном этапе каждая последовательность кодируется матрицей размером 4Хдлина последовательности.\n",
    "Чтобы исключить влияние таких очевидных вещей как старт или стоп кодон они маскируются нулями. \n",
    "Нейронная сеть не должна опираться на эти очевидные признаки, тк во многих данных может быть потеряны старты/стопы\n",
    "транскрипции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict={'A':[1,0,0,0],'C':[0,1,0,0],'G':[0,0,1,0],'T':[0,0,0,1]}\n",
    "\n",
    "def one_hot_encoding(seq):\n",
    "    one_hot_encoded=np.zeros(shape=(4,len(seq)))\n",
    "    for i,nt in enumerate(seq):\n",
    "        one_hot_encoded[:,i]=dict[nt]\n",
    "    return one_hot_encoded\n",
    "\n",
    "one_hot_seqs=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs],dtype=np.float32),3)\n",
    "one_hot_seqs_pro=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro],dtype=np.float32),3)\n",
    "one_hot_seqs_ter=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter],dtype=np.float32),3)\n",
    "\n",
    "\n",
    "one_hot_seqs[:,:,1000:1003,:]=0\n",
    "one_hot_seqs[:,:,1997:2000,:]=0\n",
    "one_hot_seqs_pro[:,:,1000:1003,:]=0\n",
    "one_hot_seqs_ter[:,:,497:500,:]=0\n",
    "\n",
    "one_hot_seqs_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_dshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_pro_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro_dshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_ter_dshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter_dshuffle],dtype=np.float32),3)\n",
    "\n",
    "one_hot_seqs_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_sshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_pro_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_pro_sshuffle],dtype=np.float32),3)\n",
    "one_hot_seqs_ter_sshuffle=np.expand_dims(np.array([ one_hot_encoding(seq) for seq in seqs_ter_sshuffle],dtype=np.float32),3)\n",
    "\n",
    "geneIDs=np.array(geneIDs)\n",
    "categories=np_utils.to_categorical(np.array(categories),2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Архитектура нейронной сети: \n",
    "Три группы из двух сверточных слоев, \n",
    "одного пуллингового и одного dropout-слоя. Они формируют вектор признаков \n",
    "для полносвязных слоев стандартной нейронной сети (представленной в самом конце). \n",
    "Далее нейронная сеть состоит из двух полносвязных \n",
    "слоев с dropout и из решающего слоя. Везде активационные функции - это ReLU, кроме решающего слоя, \n",
    "где использована softmax функция.\n",
    "Пуллинг и дропаут слои позволяют, в том числе, не переобучать слои."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(window_size):\n",
    "                model=Sequential()\n",
    "\n",
    "                model.add(Conv2D(64,kernel_size=(4,8),padding='valid',input_shape=[4,window_size,1]))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Conv2D(128,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(128,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Conv2D(64,kernel_size=(1,8),padding='same'))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(1,8),strides=(1,8),padding='same'))\n",
    "                model.add(Dropout(0.25))\n",
    "\n",
    "                model.add(Flatten())\n",
    "                model.add(Dense(128))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dropout(0.25))\n",
    "                model.add(Dense(64))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(Dense(2))\n",
    "                model.add(Activation('softmax'))\n",
    "                return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение модели\n",
    "Распределение на обучающую и тестовую выборку\n",
    "EarlyStopping строка позволяет остановить обучение если потеря данных больше некоторого порога. Поэтому нейросеть\n",
    "может останавливаться и не доходить до конца по мере обучения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(TRAINING_ONE_HOT_SEQS,TESTING_ONE_HOT_SEQS,training_indices,testing_indices,split,test_subsample,shuffle,predictor):\n",
    "      \n",
    "      TRAINING_ONE_HOT_SEQS=TRAINING_ONE_HOT_SEQS[training_indices]\n",
    "      TESTING_ONE_HOT_SEQS=TESTING_ONE_HOT_SEQS[testing_indices]\n",
    "      TRAINING_CATEGORIES=categories[training_indices]\n",
    "      TESTING_CATEGORIES=categories[testing_indices]\n",
    "      TESTING_GENES=geneIDs[testing_indices]\n",
    "\n",
    "      LENGTH=TRAINING_ONE_HOT_SEQS.shape[2]\n",
    "      \n",
    "      callbacks = [EarlyStopping(monitor='val_loss', patience=3, verbose=0)]\n",
    "      model=build(LENGTH)\n",
    "      model.compile(loss='binary_crossentropy',optimizer='Adam',metrics=['accuracy'])\n",
    "      model.fit(x=TRAINING_ONE_HOT_SEQS,y=TRAINING_CATEGORIES,batch_size=256,epochs=40,validation_data=(TESTING_ONE_HOT_SEQS,TESTING_CATEGORIES),callbacks=callbacks)\n",
    "\n",
    "      prediction=model.predict(TESTING_ONE_HOT_SEQS)\n",
    "      predicted_categories= np.argmax(prediction,axis=1)\n",
    "      real_categories=np.argmax(TESTING_CATEGORIES,axis=1)\n",
    "      tn,fp,fn,tp=confusion_matrix(real_categories,predicted_categories).ravel()\n",
    "      test_total=tp+tn+fp+fn\n",
    "      accuracy=(tp+tn)/(test_total*1.0)\n",
    "\n",
    "      now=datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "      model.save(RESULT_DIRECTORY+\"MODEL_\"+now)\n",
    "      pickle.dump([TESTING_GENES,TESTING_CATEGORIES,prediction],open(RESULT_DIRECTORY+\"PICKLE_\"+now,'wb'))\n",
    "      with open(RESULT_DIRECTORY+'SUMMARY_FILE', \"a\") as result_file:\n",
    "         result_file.write(\"\\t\".join([now,split,test_subsample,shuffle,str(tp),str(tn),str(fp),str(fn),str(accuracy),str(test_total),predictor]))\n",
    "         result_file.write(\"\\n\")\n",
    "      del model\n",
    "      K.clear_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для статистически достоверной оценки работы модели она запускается 10 раз (каждый раз) с 5-фолд кросс-валидацией. \n",
    "(При разбиении выборки учитываются семейства).\n",
    "Три типа данных: PROMOTER, TERMINATOR, PROMOTER+TERMINATOR.\n",
    "Во время запуска обеспечивается динуклеотидное и мононуклеотидное перемешивание данных обучения.\n",
    "Всего тренируется 10\\*5\\*3\\*3=450 моделей.\n",
    "В тестовой и тренировочной выборках нет необходимости производит балансировку, тк количество высоко-экспрессируемых и неэкспрессируемых генов совпадают."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=data.columns.values[-10:]\n",
    "subsamples=['subsample1','subsample2','subsample3','subsample4','subsample5']\n",
    "\n",
    "for split in splits:\n",
    "   for test_subsample in subsamples:\n",
    "       testing_genes = data[data[split]==test_subsample].index\n",
    "       testing_genes = np.array(list(set(testing_genes).intersection(set(geneIDs))))\n",
    "       training_genes= data[data[split]!=test_subsample].index\n",
    "       training_genes= np.array(list(set(training_genes).intersection(set(geneIDs))))\n",
    "       training_indices=np.array([np.where(geneIDs==element)[0][0] for element in training_genes])\n",
    "       testing_indices=np.array([np.where(geneIDs==element)[0][0] for element in testing_genes])\n",
    "       np.random.shuffle(training_indices)\n",
    "       train_models(one_hot_seqs,               one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'None','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro,           one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'None','Pro')\n",
    "       train_models(one_hot_seqs_ter,           one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'None','Ter')\n",
    "       train_models(one_hot_seqs_dshuffle,      one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'D_Shuffle','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro_dshuffle,  one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'D_Shuffle','Pro')\n",
    "       train_models(one_hot_seqs_ter_dshuffle,  one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'D_Shuffle','Ter')\n",
    "       train_models(one_hot_seqs_sshuffle,      one_hot_seqs,      training_indices,testing_indices,split,test_subsample,'S_Shuffle','Pro_and_Ter')\n",
    "       train_models(one_hot_seqs_pro_sshuffle,  one_hot_seqs_pro,  training_indices,testing_indices,split,test_subsample,'S_Shuffle','Pro')\n",
    "       train_models(one_hot_seqs_ter_sshuffle,  one_hot_seqs_ter,  training_indices,testing_indices,split,test_subsample,'S_Shuffle','Ter')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе после обучения нейронной сети:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>20190519230105</th>\n",
       "      <th>subsample_assignment1</th>\n",
       "      <th>subsample1</th>\n",
       "      <th>None</th>\n",
       "      <th>651</th>\n",
       "      <th>665</th>\n",
       "      <th>193</th>\n",
       "      <th>42</th>\n",
       "      <th>0.8484848484848485</th>\n",
       "      <th>1551</th>\n",
       "      <th>Pro_and_Ter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20190519231618</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>None</td>\n",
       "      <td>558</td>\n",
       "      <td>721</td>\n",
       "      <td>137</td>\n",
       "      <td>135</td>\n",
       "      <td>0.824629</td>\n",
       "      <td>1551</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20190519232612</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>None</td>\n",
       "      <td>566</td>\n",
       "      <td>671</td>\n",
       "      <td>187</td>\n",
       "      <td>127</td>\n",
       "      <td>0.797550</td>\n",
       "      <td>1551</td>\n",
       "      <td>Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190519233230</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1551</td>\n",
       "      <td>Pro_and_Ter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190519233924</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>693</td>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446809</td>\n",
       "      <td>1551</td>\n",
       "      <td>Pro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190519234349</td>\n",
       "      <td>subsample_assignment1</td>\n",
       "      <td>subsample1</td>\n",
       "      <td>D_Shuffle</td>\n",
       "      <td>654</td>\n",
       "      <td>25</td>\n",
       "      <td>833</td>\n",
       "      <td>39</td>\n",
       "      <td>0.437782</td>\n",
       "      <td>1551</td>\n",
       "      <td>Ter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   20190519230105  subsample_assignment1  subsample1       None  651  665  \\\n",
       "0  20190519231618  subsample_assignment1  subsample1       None  558  721   \n",
       "1  20190519232612  subsample_assignment1  subsample1       None  566  671   \n",
       "2  20190519233230  subsample_assignment1  subsample1  D_Shuffle  693    0   \n",
       "3  20190519233924  subsample_assignment1  subsample1  D_Shuffle  693    0   \n",
       "4  20190519234349  subsample_assignment1  subsample1  D_Shuffle  654   25   \n",
       "\n",
       "   193   42  0.8484848484848485  1551  Pro_and_Ter  \n",
       "0  137  135            0.824629  1551          Pro  \n",
       "1  187  127            0.797550  1551          Ter  \n",
       "2  858    0            0.446809  1551  Pro_and_Ter  \n",
       "3  858    0            0.446809  1551          Pro  \n",
       "4  833   39            0.437782  1551          Ter  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import pandas as pd\n",
    "gene_df=pd.read_csv(\"output_un_vs_high .csv\", sep=\",\")\n",
    "gene_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
